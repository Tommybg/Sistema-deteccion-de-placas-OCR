#!/usr/bin/env python3
"""
================================================================================
SCRIPT 03: EXPORTACI√ìN A TENSORFLOW LITE PARA EDGE DEVICES
================================================================================
Este script convierte el modelo YOLOv11 entrenado a formato TensorFlow Lite,
optimizado para dispositivos edge como Coral TPU, Raspberry Pi, etc.

Formatos de exportaci√≥n:
- TFLite FP32: Precisi√≥n completa
- TFLite FP16: Media precisi√≥n (m√°s r√°pido)
- TFLite INT8: Cuantizado (m√°s eficiente en edge)
- Edge TPU: Optimizado espec√≠ficamente para Coral

Autor: Sistema ANPR Colombia
Fecha: 2025
================================================================================
"""

import os
import sys
from pathlib import Path
import argparse
import shutil
from datetime import datetime

# Configuraci√≥n de rutas
PROJECT_DIR = Path(__file__).parent.parent
MODELS_DIR = PROJECT_DIR / "models"
OUTPUT_DIR = PROJECT_DIR / "output"
DATASET_DIR = PROJECT_DIR / "dataset_combinado"

# Nombre del modelo entrenado
DEFAULT_MODEL = MODELS_DIR / "placa_detector_yolo11n.pt"


def verificar_requisitos():
    """Verifica que todos los requisitos est√©n instalados."""
    print("üîç Verificando requisitos...")

    requisitos_faltantes = []

    try:
        from ultralytics import YOLO
        print("   ‚úÖ ultralytics")
    except ImportError:
        requisitos_faltantes.append("ultralytics")

    try:
        import tensorflow as tf
        print(f"   ‚úÖ TensorFlow {tf.__version__}")
    except ImportError:
        requisitos_faltantes.append("tensorflow")

    try:
        import onnx
        print(f"   ‚úÖ ONNX {onnx.__version__}")
    except ImportError:
        requisitos_faltantes.append("onnx")

    try:
        import onnx2tf
        print("   ‚úÖ onnx2tf")
    except ImportError:
        # onnx2tf es opcional
        print("   ‚ö†Ô∏è  onnx2tf no instalado (opcional para conversi√≥n avanzada)")

    if requisitos_faltantes:
        print(f"\n‚ùå Faltan dependencias: {', '.join(requisitos_faltantes)}")
        print("   Ejecuta: pip install ultralytics tensorflow onnx onnx2tf")
        return False

    return True


def encontrar_mejor_modelo():
    """Encuentra el mejor modelo entrenado."""
    # Primero buscar en la carpeta models
    if DEFAULT_MODEL.exists():
        return DEFAULT_MODEL

    # Buscar en las carpetas de output
    modelos = list(OUTPUT_DIR.rglob("**/weights/best.pt"))
    if modelos:
        # Ordenar por fecha de modificaci√≥n (m√°s reciente primero)
        modelos.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return modelos[0]

    return None


def exportar_tflite_fp32(model, output_dir: Path) -> Path:
    """
    Exporta el modelo a TFLite con precisi√≥n FP32.

    Args:
        model: Modelo YOLO cargado
        output_dir: Directorio de salida

    Returns:
        Path al modelo exportado
    """
    print("\nüì¶ Exportando a TFLite FP32...")

    try:
        # Exportar usando ultralytics
        exported = model.export(
            format="tflite",
            imgsz=640,
            half=False,
            int8=False,
        )
        print(f"   ‚úÖ Exportado: {exported}")
        return Path(exported)
    except Exception as e:
        print(f"   ‚ùå Error en exportaci√≥n FP32: {e}")
        return None


def exportar_tflite_fp16(model, output_dir: Path) -> Path:
    """
    Exporta el modelo a TFLite con precisi√≥n FP16 (media precisi√≥n).

    Args:
        model: Modelo YOLO cargado
        output_dir: Directorio de salida

    Returns:
        Path al modelo exportado
    """
    print("\nüì¶ Exportando a TFLite FP16...")

    try:
        exported = model.export(
            format="tflite",
            imgsz=640,
            half=True,
            int8=False,
        )
        print(f"   ‚úÖ Exportado: {exported}")
        return Path(exported)
    except Exception as e:
        print(f"   ‚ùå Error en exportaci√≥n FP16: {e}")
        return None


def exportar_tflite_int8(model, output_dir: Path, data_yaml: str = None) -> Path:
    """
    Exporta el modelo a TFLite cuantizado INT8.
    Requiere datos de calibraci√≥n para cuantizaci√≥n.

    Args:
        model: Modelo YOLO cargado
        output_dir: Directorio de salida
        data_yaml: Path al data.yaml para calibraci√≥n

    Returns:
        Path al modelo exportado
    """
    print("\nüì¶ Exportando a TFLite INT8 (cuantizado)...")

    try:
        exported = model.export(
            format="tflite",
            imgsz=640,
            half=False,
            int8=True,
            data=data_yaml,  # Datos para calibraci√≥n
        )
        print(f"   ‚úÖ Exportado: {exported}")
        return Path(exported)
    except Exception as e:
        print(f"   ‚ùå Error en exportaci√≥n INT8: {e}")
        return None


def exportar_edgetpu(model, output_dir: Path) -> Path:
    """
    Exporta el modelo optimizado para Coral Edge TPU.

    Nota: Requiere el compilador Edge TPU instalado.
    https://coral.ai/docs/edgetpu/compiler/

    Args:
        model: Modelo YOLO cargado
        output_dir: Directorio de salida

    Returns:
        Path al modelo exportado
    """
    print("\nüì¶ Exportando para Edge TPU...")

    try:
        exported = model.export(
            format="edgetpu",
            imgsz=640,
        )
        print(f"   ‚úÖ Exportado: {exported}")
        return Path(exported)
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Error en exportaci√≥n Edge TPU: {e}")
        print("   Nota: Requiere el compilador Edge TPU instalado")
        print("   Instalar: https://coral.ai/docs/edgetpu/compiler/")
        return None


def exportar_onnx(model, output_dir: Path) -> Path:
    """
    Exporta el modelo a formato ONNX (intermedio).

    Args:
        model: Modelo YOLO cargado
        output_dir: Directorio de salida

    Returns:
        Path al modelo exportado
    """
    print("\nüì¶ Exportando a ONNX...")

    try:
        exported = model.export(
            format="onnx",
            imgsz=640,
            simplify=True,
            dynamic=False,
        )
        print(f"   ‚úÖ Exportado: {exported}")
        return Path(exported)
    except Exception as e:
        print(f"   ‚ùå Error en exportaci√≥n ONNX: {e}")
        return None


def exportar_saved_model(model, output_dir: Path) -> Path:
    """
    Exporta el modelo a TensorFlow SavedModel.

    Args:
        model: Modelo YOLO cargado
        output_dir: Directorio de salida

    Returns:
        Path al modelo exportado
    """
    print("\nüì¶ Exportando a TensorFlow SavedModel...")

    try:
        exported = model.export(
            format="saved_model",
            imgsz=640,
        )
        print(f"   ‚úÖ Exportado: {exported}")
        return Path(exported)
    except Exception as e:
        print(f"   ‚ùå Error en exportaci√≥n SavedModel: {e}")
        return None


def validar_tflite(tflite_path: Path):
    """
    Valida que el modelo TFLite funcione correctamente.

    Args:
        tflite_path: Path al modelo TFLite
    """
    import tensorflow as tf
    import numpy as np

    print(f"\nüîç Validando modelo: {tflite_path.name}")

    try:
        # Cargar modelo
        interpreter = tf.lite.Interpreter(model_path=str(tflite_path))
        interpreter.allocate_tensors()

        # Obtener detalles de entrada/salida
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        print(f"   üì• Entrada:")
        for inp in input_details:
            print(f"      ‚Ä¢ Shape: {inp['shape']}")
            print(f"      ‚Ä¢ Dtype: {inp['dtype']}")

        print(f"   üì§ Salida:")
        for out in output_details:
            print(f"      ‚Ä¢ Shape: {out['shape']}")
            print(f"      ‚Ä¢ Dtype: {out['dtype']}")

        # Test con datos aleatorios
        input_shape = input_details[0]['shape']
        input_data = np.random.rand(*input_shape).astype(np.float32)
        interpreter.set_tensor(input_details[0]['index'], input_data)
        interpreter.invoke()

        output_data = interpreter.get_tensor(output_details[0]['index'])
        print(f"   ‚úÖ Inferencia de prueba exitosa")
        print(f"      ‚Ä¢ Output shape: {output_data.shape}")

        # Tama√±o del modelo
        size_mb = tflite_path.stat().st_size / (1024 * 1024)
        print(f"   üìä Tama√±o: {size_mb:.2f} MB")

        return True

    except Exception as e:
        print(f"   ‚ùå Error en validaci√≥n: {e}")
        return False


def organizar_modelos_exportados(output_dir: Path):
    """
    Organiza todos los modelos exportados en una carpeta limpia.

    Args:
        output_dir: Directorio donde est√°n los modelos
    """
    print("\nüìÅ Organizando modelos exportados...")

    export_dir = MODELS_DIR / "tflite_exports"
    export_dir.mkdir(parents=True, exist_ok=True)

    # Buscar todos los modelos TFLite generados
    for tflite in output_dir.parent.rglob("*.tflite"):
        destino = export_dir / tflite.name
        shutil.copy2(tflite, destino)
        print(f"   ‚úÖ Copiado: {tflite.name}")

    print(f"\nüìÇ Modelos disponibles en: {export_dir}")


def parse_args():
    """Parsea los argumentos de l√≠nea de comandos."""
    parser = argparse.ArgumentParser(
        description="Exportaci√≥n de modelo YOLO a TensorFlow Lite"
    )

    parser.add_argument(
        "--modelo", type=str, default=None,
        help="Ruta al modelo .pt entrenado"
    )
    parser.add_argument(
        "--formato", type=str, default="all",
        choices=["fp32", "fp16", "int8", "edgetpu", "onnx", "saved_model", "all"],
        help="Formato de exportaci√≥n (default: all)"
    )
    parser.add_argument(
        "--validar", action="store_true", default=True,
        help="Validar modelos exportados"
    )
    parser.add_argument(
        "--data", type=str, default=None,
        help="Ruta a data.yaml para calibraci√≥n INT8"
    )
    parser.add_argument(
        "--coco", action="store_true",
        help="Tambi√©n exportar el modelo COCO (yolo11n.pt) para detecci√≥n de veh√≠culos"
    )
    parser.add_argument(
        "--brand", action="store_true",
        help="Tambi√©n exportar el modelo de marca (marca_detector_yolo11n.pt)"
    )

    return parser.parse_args()


def main():
    """Funci√≥n principal del script."""
    print("=" * 70)
    print("   EXPORTACI√ìN A TENSORFLOW LITE")
    print("   Para dispositivos Edge (Coral TPU, Raspberry Pi, etc.)")
    print("=" * 70)

    args = parse_args()

    # Verificar requisitos
    if not verificar_requisitos():
        sys.exit(1)

    # Encontrar modelo
    if args.modelo:
        model_path = Path(args.modelo)
    else:
        model_path = encontrar_mejor_modelo()

    if model_path is None or not model_path.exists():
        print(f"\n‚ùå No se encontr√≥ el modelo entrenado")
        print(f"   Ejecuta primero: python 02_entrenar_modelo.py")
        sys.exit(1)

    print(f"\nüì¶ Modelo a exportar: {model_path}")

    # Cargar modelo
    from ultralytics import YOLO
    model = YOLO(str(model_path))

    # Directorio de salida
    output_dir = MODELS_DIR / "exports"
    output_dir.mkdir(parents=True, exist_ok=True)

    # Data yaml para calibraci√≥n
    data_yaml = args.data
    if data_yaml is None:
        data_yaml_path = DATASET_DIR / "data.yaml"
        if data_yaml_path.exists():
            data_yaml = str(data_yaml_path)

    # Exportar seg√∫n formato seleccionado
    modelos_exportados = {}

    if args.formato in ["fp32", "all"]:
        result = exportar_tflite_fp32(model, output_dir)
        if result:
            modelos_exportados["fp32"] = result

    if args.formato in ["fp16", "all"]:
        result = exportar_tflite_fp16(model, output_dir)
        if result:
            modelos_exportados["fp16"] = result

    if args.formato in ["int8", "all"]:
        result = exportar_tflite_int8(model, output_dir, data_yaml)
        if result:
            modelos_exportados["int8"] = result

    if args.formato in ["onnx", "all"]:
        result = exportar_onnx(model, output_dir)
        if result:
            modelos_exportados["onnx"] = result

    if args.formato in ["saved_model", "all"]:
        result = exportar_saved_model(model, output_dir)
        if result:
            modelos_exportados["saved_model"] = result

    if args.formato in ["edgetpu", "all"]:
        result = exportar_edgetpu(model, output_dir)
        if result:
            modelos_exportados["edgetpu"] = result

    # Validar modelos exportados
    if args.validar:
        print("\n" + "=" * 70)
        print("   VALIDACI√ìN DE MODELOS")
        print("=" * 70)

        for nombre, path in modelos_exportados.items():
            if path and path.suffix == ".tflite":
                validar_tflite(path)

    # Exportar modelo COCO para detecci√≥n de veh√≠culos
    if args.coco:
        coco_model_path = Path(__file__).parent / "yolo11n.pt"
        if coco_model_path.exists():
            print("\n" + "=" * 70)
            print("   EXPORTACI√ìN MODELO COCO (DETECCI√ìN DE VEH√çCULOS)")
            print("=" * 70)
            coco_model = YOLO(str(coco_model_path))
            try:
                coco_exported = coco_model.export(
                    format="tflite",
                    imgsz=640,
                    int8=True,
                    data=data_yaml,
                )
                if coco_exported:
                    coco_path = Path(coco_exported)
                    dest = MODELS_DIR / "tflite_exports" / "yolo11n_coco_vehicle_int8.tflite"
                    dest.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(coco_path, dest)
                    modelos_exportados["coco_vehicle_int8"] = dest
                    print(f"   ‚úÖ Modelo COCO exportado: {dest}")
            except Exception as e:
                print(f"   ‚ùå Error exportando modelo COCO: {e}")
        else:
            print(f"   ‚ö†Ô∏è  Modelo COCO no encontrado: {coco_model_path}")

    # Exportar modelo de marca vehicular
    if args.brand:
        brand_model_path = MODELS_DIR / "marca_detector_yolo11n.pt"
        if brand_model_path.exists():
            print("\n" + "=" * 70)
            print("   EXPORTACI√ìN MODELO MARCA (DETECCI√ìN DE LOGOS)")
            print("=" * 70)
            brand_model = YOLO(str(brand_model_path))

            # Usar data.yaml de marcas para calibraci√≥n INT8
            brand_data_yaml = str(PROJECT_DIR / "dataset_marcas_combinado" / "data.yaml")
            if not Path(brand_data_yaml).exists():
                brand_data_yaml = data_yaml  # Fallback

            try:
                brand_exported = brand_model.export(
                    format="tflite",
                    imgsz=640,
                    int8=True,
                    data=brand_data_yaml,
                )
                if brand_exported:
                    brand_path = Path(brand_exported)
                    dest = MODELS_DIR / "tflite_exports" / "marca_detector_yolo11n_int8.tflite"
                    dest.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(brand_path, dest)
                    modelos_exportados["brand_int8"] = dest
                    print(f"   ‚úÖ Modelo de marca exportado: {dest}")
            except Exception as e:
                print(f"   ‚ùå Error exportando modelo de marca: {e}")
        else:
            print(f"   ‚ö†Ô∏è  Modelo de marca no encontrado: {brand_model_path}")
            print(f"   Ejecuta primero: python scripts/06_entrenar_marca.py")

    # Organizar modelos
    organizar_modelos_exportados(output_dir)

    # Resumen
    print("\n" + "=" * 70)
    print("   RESUMEN DE EXPORTACI√ìN")
    print("=" * 70)
    print(f"\n‚úÖ Modelos exportados exitosamente:")
    for nombre, path in modelos_exportados.items():
        if path:
            size_mb = path.stat().st_size / (1024 * 1024) if path.exists() else 0
            print(f"   ‚Ä¢ {nombre}: {path.name} ({size_mb:.2f} MB)")

    print(f"\nüìÇ Ubicaci√≥n: {MODELS_DIR / 'tflite_exports'}")
    print(f"\nüìç Siguiente paso: Ejecutar 04_inferencia_tiempo_real.py")
    print("=" * 70)


if __name__ == "__main__":
    main()
